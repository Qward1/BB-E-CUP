import numpy as np
import pandas as pd
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import f1_score, confusion_matrix, classification_report
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
import warnings

warnings.filterwarnings('ignore')


class OptimizedCounterfeitDetector:
    """
    –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å train/test
    """

    def __init__(self, random_state=42):
        self.random_state = random_state
        self.model = None
        self.threshold = 0.5
        self.important_features = None
        self.feature_stats = {}

    def analyze_data_quality(self, train_df, test_df):
        """
        –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö –∏ —Ä–∞–∑–ª–∏—á–∏–π train/test
        """
        print("=" * 70)
        print("–ê–ù–ê–õ–ò–ó –î–ê–ù–ù–´–•")
        print("=" * 70)

        print(f"\n–†–∞–∑–º–µ—Ä—ã:")
        print(f"Train: {train_df.shape}")
        print(f"Test: {test_df.shape}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
        train_nulls = train_df.isnull().sum()
        test_nulls = test_df.isnull().sum()

        print(f"\n–ü—Ä–æ–ø—É—Å–∫–∏ –≤ train (—Ç–æ–ø-10):")
        print(train_nulls[train_nulls > 0].sort_values(ascending=False).head(10))

        print(f"\n–ü—Ä–æ–ø—É—Å–∫–∏ –≤ test (—Ç–æ–ø-10):")
        print(test_nulls[test_nulls > 0].sort_values(ascending=False).head(10))

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö
        categorical_cols = ['brand_name', 'CommercialTypeName4', 'SellerID']

        for col in categorical_cols:
            if col in train_df.columns and col in test_df.columns:
                train_unique = set(train_df[col].dropna().unique())
                test_unique = set(test_df[col].dropna().unique())

                only_in_test = test_unique - train_unique
                only_in_train = train_unique - test_unique

                print(f"\n{col}:")
                print(f"  –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≤ train: {len(train_unique)}")
                print(f"  –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≤ test: {len(test_unique)}")
                print(f"  –¢–æ–ª—å–∫–æ –≤ test: {len(only_in_test)} ({len(only_in_test) / len(test_unique) * 100:.1f}%)")
                print(f"  –¢–æ–ª—å–∫–æ –≤ train: {len(only_in_train)} ({len(only_in_train) / len(train_unique) * 100:.1f}%)")

        return train_nulls, test_nulls

    def create_stable_features(self, df, is_train=True):
        """
        –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ —Ö–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞—é—Ç –Ω–∞ test
        """
        print("\n–°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")

        df = df.copy()

        # 1. –ë–∞–∑–æ–≤—ã–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è (–Ω–µ –∑–∞–≤–∏—Å—è—Ç –æ—Ç –∞–±—Å–æ–ª—é—Ç–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π)
        # –†–µ–π—Ç–∏–Ω–≥–∏
        if 'total_ratings' in df.columns:
            df['has_ratings'] = (df['total_ratings'] > 0).astype(int)
            df['low_ratings_flag'] = (df['total_ratings'] < 10).astype(int)
            df['high_ratings_flag'] = (df['total_ratings'] > 100).astype(int)

        # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è —Ä–µ–π—Ç–∏–Ω–≥–æ–≤ (—É—Å—Ç–æ–π—á–∏–≤—ã –∫ –º–∞—Å—à—Ç–∞–±—É)
        if 'rating_5_ratio' in df.columns and 'rating_1_ratio' in df.columns:
            df['positive_negative_ratio'] = df['rating_5_ratio'] / (df['rating_1_ratio'] + 0.001)
            df['extreme_ratings'] = df['rating_1_ratio'] + df['rating_5_ratio']

        # 2. –ê–Ω–æ–º–∞–ª–∏–∏ –≤ –≤–æ–∑–≤—Ä–∞—Ç–∞—Ö (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏)
        if 'return_rate_30d' in df.columns:
            df['high_return_flag'] = (df['return_rate_30d'] > 0.3).astype(int)
            df['suspicious_returns'] = (df['return_rate_30d'] > 0.5).astype(int)

        # 3. –ü–∞—Ç—Ç–µ—Ä–Ω—ã –ø—Ä–æ–¥–∞–≤—Ü–∞ (–∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ)
        if 'seller_age_months' in df.columns:
            df['new_seller'] = (df['seller_age_months'] < 6).astype(int)
            df['established_seller'] = (df['seller_age_months'] > 24).astype(int)

        # 4. –¶–µ–Ω–æ–≤—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏ (–∫–≤–∞–Ω—Ç–∏–ª–∏)
        if 'PriceDiscounted' in df.columns:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–≤–∞–Ω—Ç–∏–ª–∏ –¥–ª—è —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏
            price_q1 = df['PriceDiscounted'].quantile(0.25)
            price_q3 = df['PriceDiscounted'].quantile(0.75)
            df['price_outlier'] = ((df['PriceDiscounted'] < price_q1 * 0.5) |
                                   (df['PriceDiscounted'] > price_q3 * 2)).astype(int)

        # 5. –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã —Ä–∏—Å–∫–∞
        risk_score = 0

        if 'fake_return_rate_30d' in df.columns:
            risk_score += (df['fake_return_rate_30d'] > 0).astype(int) * 2

        if 'return_anomaly_score' in df.columns:
            risk_score += (df['return_anomaly_score'] > df['return_anomaly_score'].quantile(0.9)).astype(int)

        if 'rating_anomaly_score' in df.columns:
            risk_score += (df['rating_anomaly_score'] > df['rating_anomaly_score'].quantile(0.9)).astype(int)

        df['risk_level'] = risk_score

        # 6. –£–±–∏—Ä–∞–µ–º –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        unstable_features = [
            'item_id', 'SellerID',  # ID –º–æ–≥—É—Ç –±—ã—Ç—å —Ä–∞–∑–Ω—ã–µ –≤ test
            'GmvTotal7', 'GmvTotal30', 'GmvTotal90',  # –ê–±—Å–æ–ª—é—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
            'ExemplarAcceptedCountTotal7', 'ExemplarAcceptedCountTotal30',  # –ú–æ–≥—É—Ç —Å–∏–ª—å–Ω–æ –æ—Ç–ª–∏—á–∞—Ç—å—Å—è
        ]

        for feature in unstable_features:
            if feature in df.columns:
                df = df.drop(columns=[feature])

        return df

    def select_best_features(self, X_train, y_train, max_features=80):
        """
        –í—ã–±–æ—Ä –ª—É—á—à–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å —É—á–µ—Ç–æ–º —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        """
        print(f"\n–í—ã–±–æ—Ä —Ç–æ–ø-{max_features} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")

        # –ò—Å–∫–ª—é—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞
        base_features = [col for col in X_train.columns
                         if not col.startswith(('embed_', 'namerus_embed_'))]

        # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ –≥–ª–∞–≤–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        embed_features = [f'embed_{i}' for i in range(5) if f'embed_{i}' in X_train.columns]
        namerus_features = [f'namerus_embed_{i}' for i in range(5) if f'namerus_embed_{i}' in X_train.columns]

        selected_features = base_features + embed_features + namerus_features

        # –û–±—É—á–∞–µ–º –ª–µ–≥–∫—É—é –º–æ–¥–µ–ª—å –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –≤–∞–∂–Ω–æ—Å—Ç–∏
        temp_model = XGBClassifier(
            n_estimators=50,
            max_depth=4,
            random_state=self.random_state,
            verbosity=0
        )

        temp_model.fit(X_train[selected_features].fillna(0), y_train)

        # –ü–æ–ª—É—á–∞–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å
        importance = pd.DataFrame({
            'feature': selected_features,
            'importance': temp_model.feature_importances_
        }).sort_values('importance', ascending=False)

        # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ø –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        self.important_features = importance.head(max_features)['feature'].tolist()

        print(f"–í—ã–±—Ä–∞–Ω–æ {len(self.important_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        print("\n–¢–æ–ø-15 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
        print(importance.head(15)[['feature', 'importance']])

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
        for feature in self.important_features:
            if feature in X_train.columns:
                self.feature_stats[feature] = {
                    'mean': X_train[feature].mean(),
                    'std': X_train[feature].std() + 1e-6
                }

        return self.important_features

    def normalize_features(self, X, is_train=False):
        """
        –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        """
        X_normalized = X.copy()

        for feature in self.important_features:
            if feature in X_normalized.columns and feature in self.feature_stats:
                stats = self.feature_stats[feature]
                X_normalized[feature] = (X_normalized[feature] - stats['mean']) / stats['std']
                # –û–±—Ä–µ–∑–∞–µ–º –≤—ã–±—Ä–æ—Å—ã
                X_normalized[feature] = X_normalized[feature].clip(-3, 3)

        return X_normalized

    def train_conservative_model(self, X_train, y_train, X_val, y_val):
        """
        –û–±—É—á–µ–Ω–∏–µ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–æ–π –º–æ–¥–µ–ª–∏ —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
        """
        print("\n" + "=" * 70)
        print("–û–ë–£–ß–ï–ù–ò–ï –ö–û–ù–°–ï–†–í–ê–¢–ò–í–ù–û–ô –ú–û–î–ï–õ–ò")
        print("=" * 70)

        scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1])

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
        params = {
            'n_estimators': 150,
            'max_depth': 5,  # –û—á–µ–Ω—å –º–µ–ª–∫–∏–µ –¥–µ—Ä–µ–≤—å—è
            'learning_rate': 0.03,  # –ú–µ–¥–ª–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
            'subsample': 0.7,
            'colsample_bytree': 0.7,
            'colsample_bylevel': 0.7,
            'min_child_weight': 10,  # –ë–æ–ª—å—à–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏
            'gamma': 0.3,  # –°–∏–ª—å–Ω–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
            'reg_alpha': 1.0,
            'reg_lambda': 2.0,
            'scale_pos_weight': scale_pos_weight * 0.8,  # –ù–µ–º–Ω–æ–≥–æ —É–º–µ–Ω—å—à–∞–µ–º –¥–ª—è –±–∞–ª–∞–Ω—Å–∞
            'eval_metric': 'logloss',
            'use_label_encoder': False,
            'random_state': self.random_state,
            'verbosity': 0,
            'n_jobs': -1
        }

        self.model = XGBClassifier(**params)

        # –û–±—É—á–∞–µ–º —Å early stopping
        eval_set = [(X_train, y_train), (X_val, y_val)]
        self.model.fit(
            X_train, y_train,
            eval_set=eval_set,
            verbose=False
        )

        # –û—Ü–µ–Ω–∫–∞
        train_pred = self.model.predict(X_train)
        val_pred = self.model.predict(X_val)

        train_f1 = f1_score(y_train, train_pred)
        val_f1 = f1_score(y_val, val_pred)

        print(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è:")
        print(f"Train F1: {train_f1:.4f}")
        print(f"Val F1: {val_f1:.4f}")
        print(f"Overfitting gap: {train_f1 - val_f1:.4f}")

        if train_f1 - val_f1 > 0.15:
            print("‚ö†Ô∏è –í—ã—Å–æ–∫–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ! –ú–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –ø–ª–æ—Ö–æ —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞ test")

        return train_f1, val_f1

    def optimize_threshold_conservative(self, X_val, y_val):
        """
        –ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ—Ä–æ–≥–∞
        """
        print("\n" + "=" * 70)
        print("–û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –ü–û–†–û–ì–ê")
        print("=" * 70)

        y_proba = self.model.predict_proba(X_val)[:, 1]

        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ—Ä–æ–≥–∏
        thresholds = np.linspace(0.3, 0.7, 21)
        results = []

        for threshold in thresholds:
            y_pred = (y_proba >= threshold).astype(int)
            f1 = f1_score(y_val, y_pred)

            tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()
            precision = tp / (tp + fp) if (tp + fp) > 0 else 0
            recall = tp / (tp + fn) if (tp + fn) > 0 else 0

            results.append({
                'threshold': threshold,
                'f1': f1,
                'precision': precision,
                'recall': recall
            })

        results_df = pd.DataFrame(results)

        # –í—ã–±–∏—Ä–∞–µ–º –ø–æ—Ä–æ–≥ —Å –ª—É—á—à–∏–º F1, –Ω–æ –Ω–µ —Å–ª–∏—à–∫–æ–º —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–π
        best_f1_idx = results_df['f1'].idxmax()
        best_threshold = results_df.loc[best_f1_idx, 'threshold']

        # –ï—Å–ª–∏ –ø–æ—Ä–æ–≥ —Å–ª–∏—à–∫–æ–º –Ω–∏–∑–∫–∏–π –∏–ª–∏ –≤—ã—Å–æ–∫–∏–π, –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º
        if best_threshold < 0.35:
            best_threshold = 0.35
        elif best_threshold > 0.65:
            best_threshold = 0.65

        self.threshold = best_threshold

        print(f"\n–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥: {self.threshold:.3f}")
        print(f"F1 –ø—Ä–∏ —ç—Ç–æ–º –ø–æ—Ä–æ–≥–µ: {results_df.loc[best_f1_idx, 'f1']:.4f}")
        print(f"Precision: {results_df.loc[best_f1_idx, 'precision']:.4f}")
        print(f"Recall: {results_df.loc[best_f1_idx, 'recall']:.4f}")

        return self.threshold

    def fit(self, train_df, test_df, target_col='resolution'):
        """
        –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –æ–±—É—á–µ–Ω–∏—è
        """
        print("\n" + "=" * 70)
        print("–ü–û–õ–ù–´–ô –ü–ê–ô–ü–õ–ê–ô–ù")
        print("=" * 70)

        # 1. –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö
        self.analyze_data_quality(train_df, test_df)

        # 2. –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        train_df = self.create_stable_features(train_df, is_train=True)
        test_df = self.create_stable_features(test_df, is_train=False)

        # 3. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/val
        from sklearn.model_selection import train_test_split

        X = train_df.drop(columns=[target_col] if target_col in train_df.columns else [])
        y = train_df[target_col] if target_col in train_df.columns else None

        X_train, X_val, y_train, y_val = train_test_split(
            X, y, test_size=0.2, random_state=self.random_state, stratify=y
        )

        # 4. –í—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        self.select_best_features(X_train, y_train)

        # 5. –ü—Ä–∏–º–µ–Ω—è–µ–º –æ—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        X_train = X_train[self.important_features].fillna(0)
        X_val = X_val[self.important_features].fillna(0)

        # 6. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        X_train = self.normalize_features(X_train, is_train=True)
        X_val = self.normalize_features(X_val, is_train=False)

        # 7. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        train_f1, val_f1 = self.train_conservative_model(X_train, y_train, X_val, y_val)

        # 8. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ—Ä–æ–≥–∞
        self.optimize_threshold_conservative(X_val, y_val)

        # 9. –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
        y_val_pred = self.predict(X_val)
        final_f1 = f1_score(y_val, y_val_pred)

        print("\n" + "=" * 70)
        print(f"üìä –§–ò–ù–ê–õ–¨–ù–´–ô F1 –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {final_f1:.4f}")
        print("=" * 70)

        return self

    def predict(self, X):
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º –ø–æ—Ä–æ–≥–æ–º
        """
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç–µ –∂–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
        X = self.create_stable_features(X, is_train=False)

        # –í—ã–±–∏—Ä–∞–µ–º –Ω—É–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        missing_features = set(self.important_features) - set(X.columns)
        if missing_features:
            print(f"‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏: {missing_features}")
            for feature in missing_features:
                X[feature] = 0

        X = X[self.important_features].fillna(0)
        X = self.normalize_features(X, is_train=False)

        # –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        y_proba = self.model.predict_proba(X)[:, 1]

        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–æ—Ä–æ–≥
        predictions = (y_proba >= self.threshold).astype(int)

        return predictions

    def predict_proba(self, X):
        """
        –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        """
        X = self.create_stable_features(X, is_train=False)

        missing_features = set(self.important_features) - set(X.columns)
        for feature in missing_features:
            X[feature] = 0

        X = X[self.important_features].fillna(0)
        X = self.normalize_features(X, is_train=False)

        return self.model.predict_proba(X)[:, 1]


# ========================================
# –ö–†–û–°–°-–í–ê–õ–ò–î–ê–¶–ò–Ø –î–õ–Ø –û–¶–ï–ù–ö–ò –°–¢–ê–ë–ò–õ–¨–ù–û–°–¢–ò
# ========================================



# ========================================
# –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø
# ========================================




# ========================================
# –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï
# ========================================

