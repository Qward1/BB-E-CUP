"""
–ï–¥–∏–Ω—ã–π –º–æ–¥—É–ª—å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–∞–Ω–Ω—ã–º–∏
–û–±—ä–µ–¥–∏–Ω—è–µ—Ç: –∑–∞–≥—Ä—É–∑–∫—É, –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –ø–∞–º—è—Ç–∏, –æ–±—Ä–∞–±–æ—Ç–∫—É –ø—Ä–æ–ø—É—Å–∫–æ–≤
"""

import pandas as pd
import numpy as np
import pyarrow.parquet as pq
from pathlib import Path
from typing import Generator, Tuple, Optional


class DataProcessor:
    """–ï–¥–∏–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ü–∏–π —Å –¥–∞–Ω–Ω—ã–º–∏"""

    def __init__(self, config: dict):
        self.config = config
        self.batch_size = config['data']['batch_size']

    @staticmethod
    def optimize_memory(df: pd.DataFrame) -> pd.DataFrame:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏"""
        for col in df.columns:
            col_type = df[col].dtype

            if col_type != 'object':
                c_min, c_max = df[col].min(), df[col].max()

                if str(col_type)[:3] == 'int':
                    if c_min > -128 and c_max < 127:
                        df[col] = df[col].astype(np.int8)
                    elif c_min > -32768 and c_max < 32767:
                        df[col] = df[col].astype(np.int16)
                    elif c_min > -2147483648 and c_max < 2147483647:
                        df[col] = df[col].astype(np.int32)
                else:
                    if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                        df[col] = df[col].astype(np.float32)
            else:
                if df[col].nunique() / len(df[col]) < 0.5:
                    df[col] = df[col].astype('category')

        return df

    def load_train_data(self, path: str, sample_size: Optional[int] = None) -> pd.DataFrame:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        if path.endswith('.parquet'):
            df = pd.read_parquet(path)
        else:
            df = pd.read_csv(path)
            df = self.optimize_memory(df)

        if sample_size and len(df) > sample_size:
            df = df.sample(sample_size, random_state=self.config['project']['seed'])

        return df

    def load_test_batches(self, path: str) -> Generator[pd.DataFrame, None, None]:
        """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –±–∞—Ç—á–µ–π –¥–ª—è inference"""
        if path.endswith('.parquet'):
            parquet_file = pq.ParquetFile(path)
            for batch in parquet_file.iter_batches(batch_size=self.batch_size):
                yield self.optimize_memory(batch.to_pandas())
        else:
            for chunk in pd.read_csv(path, chunksize=self.batch_size):
                yield self.optimize_memory(chunk)

    def prepare_features(self, df: pd.DataFrame) -> Tuple[pd.Series, pd.DataFrame, pd.DataFrame]:
        """–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —Ç–µ–∫—Å—Ç, –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏ –º–µ—Ç–∫–∏"""
        # –¢–µ–∫—Å—Ç
        text_cols = self.config['data']['text_columns']
        available_text = [col for col in text_cols if col in df.columns]

        if available_text:
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø–æ–ª—è
            texts = df[available_text].fillna('').agg(' '.join, axis=1)
        else:
            texts = pd.Series([''] * len(df))

        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        meta_cols = self.config['data']['metadata_columns']
        available_meta = [col for col in meta_cols if col in df.columns]

        if available_meta:
            metadata = df[available_meta].copy()
        else:
            metadata = pd.DataFrame(index=df.index)

        # –ú–µ—Ç–∫–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        target_col = self.config['data']['target_column']
        labels = df[target_col] if target_col in df.columns else None

        return texts, metadata, labels

    def handle_missing(self, metadata: pd.DataFrame) -> pd.DataFrame:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö"""
        # –ß–∏—Å–ª–æ–≤—ã–µ - –º–µ–¥–∏–∞–Ω–∞
        numeric_cols = metadata.select_dtypes(include=[np.number]).columns
        for col in numeric_cols:
            metadata[col].fillna(metadata[col].median(), inplace=True)

        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ - –º–æ–¥–∞ –∏–ª–∏ 'unknown'
        categorical_cols = metadata.select_dtypes(include=['object', 'category']).columns
        for col in categorical_cols:
            if metadata[col].mode().empty:
                metadata[col].fillna('unknown', inplace=True)
            else:
                metadata[col].fillna(metadata[col].mode()[0], inplace=True)

        return metadata

    def extract_counterfeit_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–æ–Ω—Ç—Ä–∞—Ñ–∞–∫—Ç–∞

        Args:
            df: DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏:
                - id, brand_name, name_rus, CommercialTypeName4
                - rating_1_count, rating_2_count, rating_3_count, rating_4_count, rating_5_count
                - comments_published_count, photos_published_count, videos_published_count
                - PriceDiscounted, item_time_alive
                - item_count_fake_returns7/30/90, item_count_sales7/30/90, item_count_returns7/30/90
                - GmvTotal7/30/90, ExemplarAcceptedCountTotal7/30/90
                - OrderAcceptedCountTotal7/30/90, ExemplarReturnedCountTotal7/30/90
                - ExemplarReturnedValueTotal7/30/90
                - ItemVarietyCount, ItemAvailableCount, seller_time_alive
                - ItemID, SellerID

        Returns:
            DataFrame —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ –∏ –Ω–æ–≤—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        """

        # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞
        result_df = df.copy()

        # ========================================
        # 1. –ü–†–ò–ó–ù–ê–ö–ò –ò–ó –†–ï–ô–¢–ò–ù–ì–û–í –ò –û–¢–ó–´–í–û–í
        # ========================================

        # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏ –Ω—É–ª—è–º–∏ –¥–ª—è —Ä–µ–π—Ç–∏–Ω–≥–æ–≤
        rating_cols = ['rating_1_count', 'rating_2_count', 'rating_3_count', 'rating_4_count', 'rating_5_count']
        for col in rating_cols:
            if col in result_df.columns:
                result_df[col] = result_df[col].fillna(0)

        # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤
        result_df['total_ratings'] = result_df[rating_cols].sum(axis=1)

        # –ü—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤
        for i, col in enumerate(rating_cols, 1):
            result_df[f'rating_{i}_ratio'] = result_df[col] / (result_df['total_ratings'] + 1)

        # –°—Ä–µ–¥–Ω–∏–π –≤–∑–≤–µ—à–µ–Ω–Ω—ã–π —Ä–µ–π—Ç–∏–Ω–≥
        result_df['avg_rating'] = (
                                          result_df['rating_1_count'] * 1 +
                                          result_df['rating_2_count'] * 2 +
                                          result_df['rating_3_count'] * 3 +
                                          result_df['rating_4_count'] * 4 +
                                          result_df['rating_5_count'] * 5
                                  ) / (result_df['total_ratings'] + 1)

        # –î–∏—Å–ø–µ—Ä—Å–∏—è –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤
        def calculate_rating_stats(row):
            vals = []
            for i, col in enumerate(rating_cols, 1):
                vals.extend([i] * int(row[col]))
            if vals:
                return pd.Series([np.std(vals), np.var(vals)])
            return pd.Series([0, 0])

        result_df[['rating_std', 'rating_variance']] = result_df.apply(calculate_rating_stats, axis=1)

        # –≠–Ω—Ç—Ä–æ–ø–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–µ–π—Ç–∏–Ω–≥–æ–≤
        def calculate_entropy(row):
            total = row['total_ratings']
            if total == 0:
                return 0
            entropy = 0
            for col in rating_cols:
                if row[col] > 0:
                    p = row[col] / total
                    entropy -= p * np.log(p + 1e-10)
            return entropy

        result_df['rating_entropy'] = result_df.apply(calculate_entropy, axis=1)

        # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ø–æ–ª—è—Ä–∏–∑–∞—Ü–∏–∏ (–º–Ω–æ–≥–æ –∫—Ä–∞–π–Ω–∏—Ö –æ—Ü–µ–Ω–æ–∫)
        result_df['rating_polarization'] = (
                                                   result_df['rating_1_count'] + result_df['rating_5_count']
                                           ) / (result_df['total_ratings'] + 1)

        # U-–æ–±—Ä–∞–∑–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ (–ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω)
        result_df['rating_u_shape'] = (
                                              (result_df['rating_1_count'] + result_df['rating_5_count']) -
                                              (result_df['rating_2_count'] + result_df['rating_3_count'] + result_df[
                                                  'rating_4_count'])
                                      ) / (result_df['total_ratings'] + 1)

        # –ü–µ—Ä–µ–∫–æ—Å –≤ —Å—Ç–æ—Ä–æ–Ω—É –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫
        result_df['positive_skew'] = (
                                             result_df['rating_4_count'] + result_df['rating_5_count']
                                     ) / (result_df['total_ratings'] + 1)

        # –ü–µ—Ä–µ–∫–æ—Å –≤ —Å—Ç–æ—Ä–æ–Ω—É –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫
        result_df['negative_skew'] = (
                                             result_df['rating_1_count'] + result_df['rating_2_count']
                                     ) / (result_df['total_ratings'] + 1)

        # –î–æ–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫ (5 –∑–≤–µ–∑–¥)
        result_df['perfect_rating_ratio'] = result_df['rating_5_count'] / (result_df['total_ratings'] + 1)

        # –ú–µ–¥–∏–∞–Ω–∞ —Ä–µ–π—Ç–∏–Ω–≥–∞ (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è)
        def calculate_median_rating(row):
            total = row['total_ratings']
            if total == 0:
                return 0
            cumsum = 0
            median_pos = total / 2
            for i, col in enumerate(rating_cols, 1):
                cumsum += row[col]
                if cumsum >= median_pos:
                    return i
            return 5

        result_df['median_rating'] = result_df.apply(calculate_median_rating, axis=1)

        # ========================================
        # 2. –ü–†–ò–ó–ù–ê–ö–ò –ò–ó –ö–û–ú–ú–ï–ù–¢–ê–†–ò–ï–í –ò –ú–ï–î–ò–ê
        # ========================================

        # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
        media_cols = ['comments_published_count', 'photos_published_count', 'videos_published_count']
        for col in media_cols:
            if col in result_df.columns:
                result_df[col] = result_df[col].fillna(0)

        # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–µ–¥–∏–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        result_df['total_media'] = (
                result_df['photos_published_count'] +
                result_df['videos_published_count']
        )

        # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∫ —Ä–µ–π—Ç–∏–Ω–≥–∞–º
        result_df['comments_per_rating'] = (
                result_df['comments_published_count'] /
                (result_df['total_ratings'] + 1)
        )

        # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –º–µ–¥–∏–∞ –∫ —Ä–µ–π—Ç–∏–Ω–≥–∞–º
        result_df['media_per_rating'] = (
                result_df['total_media'] /
                (result_df['total_ratings'] + 1)
        )

        # –î–æ–ª—è –æ—Ç–∑—ã–≤–æ–≤ —Å —Ñ–æ—Ç–æ
        result_df['photo_review_ratio'] = (
                result_df['photos_published_count'] /
                (result_df['total_ratings'] + 1)
        )

        # –î–æ–ª—è –æ—Ç–∑—ã–≤–æ–≤ —Å –≤–∏–¥–µ–æ
        result_df['video_review_ratio'] = (
                result_df['videos_published_count'] /
                (result_df['total_ratings'] + 1)
        )

        # –§–ª–∞–≥ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö
        result_df['high_comment_activity'] = (result_df['comments_per_rating'] > 0.5).astype(int)
        result_df['no_comments_flag'] = (result_df['comments_published_count'] == 0).astype(int)

        # ========================================
        # 3. –ü–†–ò–ó–ù–ê–ö–ò –ò–ó –ü–†–û–î–ê–ñ –ò –í–û–ó–í–†–ê–¢–û–í
        # ========================================

        # –ü—Ä–æ–¥–∞–∂–∏
        sales_cols = ['item_count_sales7', 'item_count_sales30', 'item_count_sales90']
        for col in sales_cols:
            if col in result_df.columns:
                result_df[col] = result_df[col].fillna(0)

        # –î–∏–Ω–∞–º–∏–∫–∞ –ø—Ä–æ–¥–∞–∂
        result_df['sales_velocity_7d'] = result_df['item_count_sales7'] / 7
        result_df['sales_velocity_30d'] = result_df['item_count_sales30'] / 30
        result_df['sales_velocity_90d'] = result_df['item_count_sales90'] / 90

        # –£—Å–∫–æ—Ä–µ–Ω–∏–µ –ø—Ä–æ–¥–∞–∂
        result_df['sales_acceleration'] = (
                result_df['sales_velocity_7d'] - result_df['sales_velocity_30d']
        )

        # –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –ø—Ä–æ–¥–∞–∂
        result_df['sales_stability'] = 1 - abs(
            result_df['sales_velocity_7d'] - result_df['sales_velocity_30d']
        ) / (result_df['sales_velocity_30d'] + 1)

        # –í–æ–∑–≤—Ä–∞—Ç—ã
        returns_cols = ['item_count_returns7', 'item_count_returns30', 'item_count_returns90']
        for col in returns_cols:
            if col in result_df.columns:
                result_df[col] = result_df[col].fillna(0)

        # –ü—Ä–æ—Ü–µ–Ω—Ç –≤–æ–∑–≤—Ä–∞—Ç–æ–≤
        result_df['return_rate_7d'] = (
                result_df['item_count_returns7'] /
                (result_df['item_count_sales7'] + 1)
        )
        result_df['return_rate_30d'] = (
                result_df['item_count_returns30'] /
                (result_df['item_count_sales30'] + 1)
        )
        result_df['return_rate_90d'] = (
                result_df['item_count_returns90'] /
                (result_df['item_count_sales90'] + 1)
        )

        # –î–∏–Ω–∞–º–∏–∫–∞ –≤–æ–∑–≤—Ä–∞—Ç–æ–≤
        result_df['return_acceleration'] = (
                result_df['return_rate_7d'] - result_df['return_rate_30d']
        )

        # –§–µ–π–∫–æ–≤—ã–µ –≤–æ–∑–≤—Ä–∞—Ç—ã (–æ—á–µ–Ω—å –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ!)
        fake_returns_cols = ['item_count_fake_returns7', 'item_count_fake_returns30', 'item_count_fake_returns90']
        for col in fake_returns_cols:
            if col in result_df.columns:
                result_df[col] = result_df[col].fillna(0)

        # –î–æ–ª—è —Ñ–µ–π–∫–æ–≤—ã—Ö –≤–æ–∑–≤—Ä–∞—Ç–æ–≤
        result_df['fake_return_rate_7d'] = (
                result_df['item_count_fake_returns7'] /
                (result_df['item_count_returns7'] + 1)
        )
        result_df['fake_return_rate_30d'] = (
                result_df['item_count_fake_returns30'] /
                (result_df['item_count_returns30'] + 1)
        )

        # –§–ª–∞–≥ –Ω–∞–ª–∏—á–∏—è —Ñ–µ–π–∫–æ–≤—ã—Ö –≤–æ–∑–≤—Ä–∞—Ç–æ–≤
        result_df['has_fake_returns'] = (
                (result_df['item_count_fake_returns7'] > 0) |
                (result_df['item_count_fake_returns30'] > 0) |
                (result_df['item_count_fake_returns90'] > 0)
        ).astype(int)

        # ========================================
        # 4. –§–ò–ù–ê–ù–°–û–í–´–ï –ú–ï–¢–†–ò–ö–ò
        # ========================================

        # GMV (Gross Merchandise Value)
        gmv_cols = ['GmvTotal7', 'GmvTotal30', 'GmvTotal90']
        for col in gmv_cols:
            if col in result_df.columns:
                result_df[col] = result_df[col].fillna(0)

        # –°—Ä–µ–¥–Ω–∏–π —á–µ–∫
        result_df['avg_order_value_7d'] = (
                result_df['GmvTotal7'] /
                (result_df['item_count_sales7'] + 1)
        )
        result_df['avg_order_value_30d'] = (
                result_df['GmvTotal30'] /
                (result_df['item_count_sales30'] + 1)
        )
        result_df['avg_order_value_90d'] = (
                result_df['GmvTotal90'] /
                (result_df['item_count_sales90'] + 1)
        )

        # –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ —á–µ–∫–∞
        result_df['avg_order_value_change'] = (
                                                      result_df['avg_order_value_7d'] - result_df['avg_order_value_30d']
                                              ) / (result_df['avg_order_value_30d'] + 1)

        # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ü–µ–Ω—ã –∏ —Å—Ä–µ–¥–Ω–µ–≥–æ —á–µ–∫–∞
        if 'PriceDiscounted' in result_df.columns:
            result_df['PriceDiscounted'] = result_df['PriceDiscounted'].fillna(0)
            result_df['price_to_avg_order_ratio'] = (
                    result_df['PriceDiscounted'] /
                    (result_df['avg_order_value_30d'] + 1)
            )

            # –¶–µ–Ω–æ–≤–æ–π —Å–µ–≥–º–µ–Ω—Ç (–ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–∞—è —à–∫–∞–ª–∞)
            result_df['price_segment'] = np.log1p(result_df['PriceDiscounted'])

            # –§–ª–∞–≥–∏ —Ü–µ–Ω–æ–≤—ã—Ö –∞–Ω–æ–º–∞–ª–∏–π
            price_median = result_df['PriceDiscounted'].median()
            result_df['low_price_flag'] = (result_df['PriceDiscounted'] < price_median * 0.3).astype(int)
            result_df['high_price_flag'] = (result_df['PriceDiscounted'] > price_median * 3).astype(int)

        # –°—Ç–æ–∏–º–æ—Å—Ç—å –≤–æ–∑–≤—Ä–∞—Ç–æ–≤
        return_value_cols = ['ExemplarReturnedValueTotal7', 'ExemplarReturnedValueTotal30',
                             'ExemplarReturnedValueTotal90']
        for col in return_value_cols:
            if col in result_df.columns:
                result_df[col] = result_df[col].fillna(0)

        # –î–æ–ª—è –≤–æ–∑–≤—Ä–∞—Ç–æ–≤ –æ—Ç GMV
        result_df['return_value_ratio_7d'] = (
                result_df['ExemplarReturnedValueTotal7'] /
                (result_df['GmvTotal7'] + 1)
        )
        result_df['return_value_ratio_30d'] = (
                result_df['ExemplarReturnedValueTotal30'] /
                (result_df['GmvTotal30'] + 1)
        )

        # ========================================
        # 5. –ü–†–ò–ó–ù–ê–ö–ò –ê–ö–¢–ò–í–ù–û–°–¢–ò –ò –í–†–ï–ú–ï–ù–ò
        # ========================================

        # –í–æ–∑—Ä–∞—Å—Ç —Ç–æ–≤–∞—Ä–∞
        if 'item_time_alive' in result_df.columns:
            result_df['item_time_alive'] = result_df['item_time_alive'].fillna(0)
            result_df['item_age_months'] = result_df['item_time_alive'] / 30
            result_df['item_age_log'] = np.log1p(result_df['item_time_alive'])

            # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ –≤–æ–∑—Ä–∞—Å—Ç—É —Ç–æ–≤–∞—Ä–∞
            result_df['is_new_item'] = (result_df['item_time_alive'] < 30).astype(int)
            result_df['is_old_item'] = (result_df['item_time_alive'] > 365).astype(int)

            # –ü—Ä–æ–¥–∞–∂–∏ –Ω–∞ –¥–µ–Ω—å –∂–∏–∑–Ω–∏ —Ç–æ–≤–∞—Ä–∞
            result_df['sales_per_day_alive'] = (
                    result_df['item_count_sales90'] /
                    (result_df['item_time_alive'] + 1)
            )

            # –†–µ–π—Ç–∏–Ω–≥–∏ –Ω–∞ –¥–µ–Ω—å –∂–∏–∑–Ω–∏
            result_df['ratings_per_day_alive'] = (
                    result_df['total_ratings'] /
                    (result_df['item_time_alive'] + 1)
            )

        # –í–æ–∑—Ä–∞—Å—Ç –ø—Ä–æ–¥–∞–≤—Ü–∞
        if 'seller_time_alive' in result_df.columns:
            result_df['seller_time_alive'] = result_df['seller_time_alive'].fillna(0)
            result_df['seller_age_months'] = result_df['seller_time_alive'] / 30
            result_df['seller_age_years'] = result_df['seller_time_alive'] / 365
            result_df['seller_age_log'] = np.log1p(result_df['seller_time_alive'])

            # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø—Ä–æ–¥–∞–≤—Ü–æ–≤
            result_df['is_new_seller'] = (result_df['seller_time_alive'] < 30).astype(int)
            result_df['is_young_seller'] = (result_df['seller_time_alive'] < 90).astype(int)
            result_df['is_mature_seller'] = (result_df['seller_time_alive'] > 365).astype(int)

            # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –≤–æ–∑—Ä–∞—Å—Ç–∞ —Ç–æ–≤–∞—Ä–∞ –∏ –ø—Ä–æ–¥–∞–≤—Ü–∞
            result_df['item_seller_age_ratio'] = (
                    result_df['item_time_alive'] /
                    (result_df['seller_time_alive'] + 1)
            )

        # ========================================
        # 6. –ü–†–ò–ó–ù–ê–ö–ò –ó–ê–ö–ê–ó–û–í –ò –ü–†–ò–ù–Ø–¢–ò–Ø
        # ========================================

        # –ü—Ä–∏–Ω—è—Ç—ã–µ —ç–∫–∑–µ–º–ø–ª—è—Ä—ã
        accepted_cols = ['ExemplarAcceptedCountTotal7', 'ExemplarAcceptedCountTotal30', 'ExemplarAcceptedCountTotal90']
        for col in accepted_cols:
            if col in result_df.columns:
                result_df[col] = result_df[col].fillna(0)

        # –ü—Ä–∏–Ω—è—Ç—ã–µ –∑–∞–∫–∞–∑—ã
        order_cols = ['OrderAcceptedCountTotal7', 'OrderAcceptedCountTotal30', 'OrderAcceptedCountTotal90']
        for col in order_cols:
            if col in result_df.columns:
                result_df[col] = result_df[col].fillna(0)

        # –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤ –≤ –∑–∞–∫–∞–∑–µ
        result_df['items_per_order_7d'] = (
                result_df['ExemplarAcceptedCountTotal7'] /
                (result_df['OrderAcceptedCountTotal7'] + 1)
        )
        result_df['items_per_order_30d'] = (
                result_df['ExemplarAcceptedCountTotal30'] /
                (result_df['OrderAcceptedCountTotal30'] + 1)
        )

        # –ü—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–∏–Ω—è—Ç–∏—è (acceptance rate)
        result_df['acceptance_rate_7d'] = (
                result_df['ExemplarAcceptedCountTotal7'] /
                (result_df['item_count_sales7'] + result_df['ExemplarAcceptedCountTotal7'] + 1)
        )

        # ========================================
        # 7. –ü–†–ò–ó–ù–ê–ö–ò –ò–ó –¢–ï–ö–°–¢–û–í–´–• –ü–û–õ–ï–ô
        # ========================================

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ brand_name
        if 'brand_name' in result_df.columns:
            result_df['brand_clean'] = result_df['brand_name'].fillna('').astype(str).str.strip()
            result_df['brand_length'] = result_df['brand_clean'].str.len()
            result_df['brand_word_count'] = result_df['brand_clean'].str.split().str.len()
            result_df['brand_has_numbers'] = result_df['brand_clean'].str.contains(r'\d', regex=True).astype(int)
            result_df['brand_all_caps'] = (
                    (result_df['brand_clean'].str.isupper()) &
                    (result_df['brand_length'] > 2)
            ).astype(int)
            result_df['has_brand'] = (result_df['brand_length'] > 0).astype(int)

            # –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ –±—Ä–µ–Ω–¥–µ (–≤–∫–ª—é—á–∞—è ACTRUM –∏–∑ –ø—Ä–∏–º–µ—Ä–∞)
            suspicious_patterns = ['ACTRUM', 'COPY', 'REPLICA', 'TYPE', 'STYLE', 'LIKE',
                                   '–ê–ù–ê–õ–û–ì', '–ö–û–ü–ò–Ø', '–¢–ò–ü', '–ü–û–î–û–ë–ù–´–ô']
            pattern = '|'.join(suspicious_patterns)
            result_df['suspicious_brand_pattern'] = (
                result_df['brand_clean'].str.upper().str.contains(pattern, regex=True, na=False)
            ).astype(int)

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ name_rus
        if 'name_rus' in result_df.columns:
            result_df['name_clean'] = result_df['name_rus'].fillna('').astype(str).str.strip()
            result_df['name_length'] = result_df['name_clean'].str.len()
            result_df['name_word_count'] = result_df['name_clean'].str.split().str.len()
            result_df['name_has_dots'] = result_df['name_clean'].str.contains('\.\.\.', regex=True).astype(int)
            result_df['has_name'] = (result_df['name_length'] > 0).astype(int)

            # –û–±—Ä–µ–∑–∞–Ω–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ (–ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ)
            result_df['name_truncated'] = result_df['name_clean'].str.endswith('...').astype(int)

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        if 'CommercialTypeName4' in result_df.columns:
            result_df['category_clean'] = result_df['CommercialTypeName4'].fillna('').astype(str).str.strip()
            result_df['category_length'] = result_df['category_clean'].str.len()
            result_df['has_category'] = (result_df['category_length'] > 0).astype(int)

        # –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –±—Ä–µ–Ω–¥–∞ –∏ –Ω–∞–∑–≤–∞–Ω–∏—è
        if 'brand_name' in result_df.columns and 'name_rus' in result_df.columns:
            def check_brand_in_name(row):
                brand = str(row.get('brand_clean', '')).lower()
                name = str(row.get('name_clean', '')).lower()
                if brand and name and len(brand) > 2:
                    return 1 if brand in name else 0
                return 0

            result_df['brand_name_match'] = result_df.apply(check_brand_in_name, axis=1)

        # ========================================
        # 8. –ü–†–ò–ó–ù–ê–ö–ò –ò–ù–í–ï–ù–¢–ê–†–Ø
        # ========================================

        # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
        inventory_cols = ['ItemVarietyCount', 'ItemAvailableCount']
        for col in inventory_cols:
            if col in result_df.columns:
                result_df[col] = result_df[col].fillna(1)

        # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –∫ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—é
        result_df['availability_ratio'] = (
                result_df['ItemAvailableCount'] /
                (result_df['ItemVarietyCount'] + 1)
        )

        # –§–ª–∞–≥–∏ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        result_df['single_item_seller'] = (result_df['ItemVarietyCount'] == 1).astype(int)
        result_df['low_variety_flag'] = (result_df['ItemVarietyCount'] < 5).astype(int)

        # ========================================
        # 9. –ü–ï–†–ï–ö–†–ï–°–¢–ù–´–ï –ü–†–ò–ó–ù–ê–ö–ò
        # ========================================

        # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤ –∫ –ø—Ä–æ–¥–∞–∂–∞–º
        result_df['ratings_per_sale'] = (
                result_df['total_ratings'] /
                (result_df['item_count_sales90'] + 1)
        )

        # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∫ –ø—Ä–æ–¥–∞–∂–∞–º
        result_df['comments_per_sale'] = (
                result_df['comments_published_count'] /
                (result_df['item_count_sales90'] + 1)
        )

        # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –≤–æ–∑–≤—Ä–∞—Ç–æ–≤ –∫ —Ä–µ–π—Ç–∏–Ω–≥–∞–º
        result_df['returns_per_rating'] = (
                result_df['item_count_returns30'] /
                (result_df['total_ratings'] + 1)
        )

        # –ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤ –∏ –≤–æ–∑–≤—Ä–∞—Ç–æ–≤
        def calculate_return_rating_anomaly(row):
            if row['avg_rating'] > 0 and row['total_ratings'] > 0:
                # –≠–º–ø–∏—Ä–∏—á–µ—Å–∫–∞—è —Ñ–æ—Ä–º—É–ª–∞ –æ–∂–∏–¥–∞–µ–º—ã—Ö –≤–æ–∑–≤—Ä–∞—Ç–æ–≤
                expected_returns = max(0, 5 - row['avg_rating']) * row['total_ratings'] * 0.05
                actual_returns = row['item_count_returns30']
                return abs(actual_returns - expected_returns) / (expected_returns + 1)
            return 0

        result_df['return_rating_anomaly'] = result_df.apply(calculate_return_rating_anomaly, axis=1)

        # –ù–æ–≤—ã–π –ø—Ä–æ–¥–∞–≤–µ—Ü —Å –±–æ–ª—å—à–∏–º –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç–æ–º
        result_df['new_seller_high_variety'] = (
                result_df['is_new_seller'] *
                np.minimum(result_df['ItemVarietyCount'] / 10, 1)
        )

        # –ù–æ–≤—ã–π —Ç–æ–≤–∞—Ä —Å–æ –º–Ω–æ–≥–∏–º–∏ –æ—Ç–∑—ã–≤–∞–º–∏ (–ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ)
        result_df['new_item_many_reviews'] = (
                result_df['is_new_item'] *
                np.minimum(result_df['total_ratings'] / 50, 1)
        )

        # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ñ–µ–π–∫–æ–≤—ã—Ö –≤–æ–∑–≤—Ä–∞—Ç–æ–≤ –∫ –æ–±—â–∏–º –≤–æ–∑–≤—Ä–∞—Ç–∞–º
        result_df['fake_to_total_returns'] = (
                result_df['item_count_fake_returns30'] /
                (result_df['item_count_returns30'] + 1)
        )

        # ========================================
        # 10. –ö–û–ú–ü–õ–ï–ö–°–ù–´–ï –ü–û–ö–ê–ó–ê–¢–ï–õ–ò –†–ò–°–ö–ê
        # ========================================

        # –ë–∞–∑–æ–≤—ã–π risk score
        result_df['risk_score'] = (
                result_df['has_fake_returns'] * 5 +  # –§–µ–π–∫–æ–≤—ã–µ –≤–æ–∑–≤—Ä–∞—Ç—ã - —Å–∞–º—ã–π —Å–∏–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª
                result_df.get('suspicious_brand_pattern', 0) * 3 +
                result_df['is_new_seller'] * 1.5 +
                result_df['rating_u_shape'] * 2 +
                result_df['single_item_seller'] * 1 +
                (result_df['return_rate_30d'] > 0.3).astype(int) * 2 +
                result_df['new_item_many_reviews'] * 1.5 +
                (result_df['fake_to_total_returns'] > 0.1).astype(int) * 3
        )

        # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π risk score (0-1)
        max_risk = result_df['risk_score'].max()
        if max_risk > 0:
            result_df['risk_score_normalized'] = result_df['risk_score'] / max_risk
        else:
            result_df['risk_score_normalized'] = 0

        # –ê–Ω–æ–º–∞–ª—å–Ω–æ—Å—Ç—å –ø–æ –≤–æ–∑–≤—Ä–∞—Ç–∞–º
        result_df['return_anomaly_score'] = (
                result_df['return_rate_30d'] * 5 +
                result_df['fake_to_total_returns'] * 10 +
                result_df['return_acceleration'] * 2
        )

        # –ê–Ω–æ–º–∞–ª—å–Ω–æ—Å—Ç—å –ø–æ —Ä–µ–π—Ç–∏–Ω–≥–∞–º
        result_df['rating_anomaly_score'] = (
                result_df['rating_u_shape'] * 3 +
                result_df['rating_polarization'] * 2 +
                abs(result_df['avg_rating'] - result_df['median_rating']) +
                (1 - result_df['rating_entropy'] / (result_df['rating_entropy'].max() + 1))
        )

        # –ê–Ω–æ–º–∞–ª—å–Ω–æ—Å—Ç—å –ø—Ä–æ–¥–∞–≤—Ü–∞
        result_df['seller_anomaly_score'] = (
                result_df['is_new_seller'] * 2 +
                result_df['new_seller_high_variety'] * 3 +
                result_df['single_item_seller'] * 1.5 +
                (result_df['item_seller_age_ratio'] > 2).astype(int) * 1  # –¢–æ–≤–∞—Ä —Å—Ç–∞—Ä—à–µ –ø—Ä–æ–¥–∞–≤—Ü–∞
        )

        # –ê–Ω–æ–º–∞–ª—å–Ω–æ—Å—Ç—å –ø—Ä–æ–¥–∞–∂
        result_df['sales_anomaly_score'] = (
                abs(result_df['sales_acceleration']) * 2 +
                (result_df['ratings_per_sale'] > 2).astype(int) * 3 +  # –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ –ø—Ä–æ–¥–∞–∂—É
                (result_df['avg_order_value_change'] > 0.5).astype(int) * 2
        )

        # –û–±—â–∏–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å –∞–Ω–æ–º–∞–ª—å–Ω–æ—Å—Ç–∏
        result_df['total_anomaly_score'] = (
                result_df['return_anomaly_score'] * 0.3 +
                result_df['rating_anomaly_score'] * 0.25 +
                result_df['seller_anomaly_score'] * 0.25 +
                result_df['sales_anomaly_score'] * 0.2
        )

        # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –¥–ª—è –∫–æ–Ω—Ç—Ä–∞—Ñ–∞–∫—Ç–∞
        result_df['counterfeit_indicator'] = (
                result_df['has_fake_returns'] +
                result_df.get('suspicious_brand_pattern', 0) +
                (result_df['return_rate_30d'] > 0.2).astype(int) +
                (result_df['rating_u_shape'] > 0.3).astype(int) +
                (result_df['fake_to_total_returns'] > 0.05).astype(int) +
                result_df['new_seller_high_variety'] +
                result_df['new_item_many_reviews']
        )

        # ========================================
        # 11. –°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ò–ï –ê–ì–†–ï–ì–ê–¢–´
        # ========================================

        # –ü—Ä–æ—Ü–µ–Ω—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö
        text_fields = ['brand_name', 'name_rus', 'CommercialTypeName4']
        filled_count = 0
        for field in text_fields:
            if field in result_df.columns:
                filled_count += (result_df[field].notna() & (result_df[field] != '')).astype(int)

        result_df['data_completeness'] = filled_count / len(text_fields)

        # –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Ç–æ–≤–∞—Ä–∞ (–∫–æ–º–ø–æ–∑–∏—Ç–Ω—ã–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å)
        result_df['item_activity_score'] = (
                result_df['sales_velocity_30d'] * 0.4 +
                result_df['ratings_per_day_alive'] * 100 * 0.3 +
                result_df['comments_per_sale'] * 10 * 0.3
        )

        # –ö–∞—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–∞ (–∫–æ–º–ø–æ–∑–∏—Ç–Ω—ã–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å)
        result_df['quality_score'] = (
                result_df['avg_rating'] / 5 * 0.4 +
                (1 - result_df['return_rate_30d']) * 0.4 +
                (1 - result_df['fake_to_total_returns']) * 0.2
        )

        # ========================================
        # –§–ò–ù–ê–õ–¨–ù–ê–Ø –û–ß–ò–°–¢–ö–ê
        # ========================================

        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        temp_cols = ['brand_clean', 'name_clean', 'category_clean']
        for col in temp_cols:
            if col in result_df.columns:
                result_df = result_df.drop(columns=[col])

        # –ó–∞–º–µ–Ω—è–µ–º inf –Ω–∞ NaN, –∑–∞—Ç–µ–º –Ω–∞ 0
        result_df = result_df.replace([np.inf, -np.inf], np.nan)

        # –ó–∞–ø–æ–ª–Ω—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è NaN –Ω—É–ª—è–º–∏ –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        numeric_cols = result_df.select_dtypes(include=[np.number]).columns
        result_df[numeric_cols] = result_df[numeric_cols].fillna(0)

        # –ü–æ–¥—Å—á–µ—Ç –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        original_cols = df.columns.tolist()
        new_cols = [col for col in result_df.columns if col not in original_cols]
        # –í—ã–≤–æ–¥ —Ç–æ–ø –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        print("\nüìä Key features for counterfeit detection:")
        important_features = [
            'counterfeit_indicator', 'risk_score', 'total_anomaly_score',
            'has_fake_returns', 'fake_to_total_returns', 'return_rating_anomaly',
            'suspicious_brand_pattern', 'rating_u_shape', 'return_rate_30d',
            'new_seller_high_variety', 'new_item_many_reviews', 'quality_score'
        ]

        for feat in important_features:
            if feat in result_df.columns:
                print(f"  ‚úì {feat}")

        return result_df